{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"0\">Image Classification With Neural Network</a>\n",
    "\n",
    "1. <a href=\"#1\">Data Processing</a>\n",
    "2. <a href=\"#2\">Build DataSet</a>\n",
    "3. <a herf=\"#3\">Build CNN</a>\n",
    "4. <a herf=\"#4\">Loss&Optimizer</a>\n",
    "5. <a herf=\"#5\">Training&Testing</a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. <a name=\"1\">Data Processing</a>\n",
    "\n",
    "- Locate the path to the image-dataset folder\n",
    "- Transformation & Transportation\n",
    "- Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the libraries\n",
    "import glob\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the dataset\n",
    "all_imgs_path = glob.glob(r'./image_data/*/*.png')\n",
    "print(all_imgs_path[:100])\n",
    "print(\"Numbers of All Samples: \",len(all_imgs_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Labels\n",
    "species = ['bagel','donut']\n",
    "species_to_id = dict((c, i) for i, c in enumerate(species))\n",
    "id_to_species = dict((v, k) for k, v in species_to_id.items())\n",
    "print(id_to_species)\n",
    "all_labels = []\n",
    "#iter through the path of the image\n",
    "for img in all_imgs_path:\n",
    "    # Classify each img should be on which label\n",
    "    for i, c in enumerate(species):\n",
    "        if c in img:\n",
    "            all_labels.append(i)\n",
    "print(all_labels[:100]) #Get All labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. <a name=\"1\">Transpose the data</a>\n",
    "\n",
    "Transform all photos to the same size: \"96 * 96\"\n",
    "and then making sure they are all between the tensor[-1,1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transform = transforms.Compose([\n",
    "                transforms.Resize((96,96)), \n",
    "                transforms.ToTensor(), \n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a36663b3cd5f5ce184ef7e18777fe5102208357de05ea4bf310bfe3152c9c88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
